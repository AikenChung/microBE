{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Classifier_LoadAndTest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7C1h9aeyRTT4GALOPagDJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AikenChung/microBE/blob/main/NN_Classifier_LoadAndTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhtmXu8lZAdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81abcb38-4207-41fd-936b-dc718ce087b6"
      },
      "source": [
        "colab = True\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os as os\n",
        "if not os.path.exists('/content/drive/My Drive/Colab Notebooks/data'):\n",
        "    os.makedirs('/content/drive/My Drive/Colab Notebooks/data')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9W8gZtbYuIn"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn, from_numpy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import easydict\n",
        "\n",
        "if not os.path.exists('/content/drive/My Drive/Colab Notebooks/data/MLP_testResults'):\n",
        "    os.makedirs('/content/drive/My Drive/Colab Notebooks/data/MLP_testResults')\n",
        "    \n",
        "resultFilePath = '/content/drive/My Drive/Colab Notebooks/data/MLP_testResults/'    \n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\" Multi-Layer Perceptron for classifying IBD and Healthy microbiome data\"\"\"\n",
        "    def __init__(self, input_dim=1177, hidden_dim=256, \n",
        "                 hidden_layer_num=1, \n",
        "                 pre_output_dim = 64, \n",
        "                 output_dim=1):        \n",
        "        super(MLP, self).__init__()        \n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(nn.Linear(input_dim, hidden_dim))\n",
        "        for layer in range(hidden_layer_num):\n",
        "            self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "        self.layers.append(nn.Linear(hidden_dim, pre_output_dim))\n",
        "        self.layers.append(nn.Linear(pre_output_dim, output_dim))\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = torch.tanh(layer(x))\n",
        "        out = self.layers[-1](x)\n",
        "        out = torch.sigmoid(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcT8Bt8cu1cE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c2a218-277f-4855-e83b-bf725d992707"
      },
      "source": [
        "\n",
        "#================================== Setting ==================================\n",
        "\n",
        "# Load the saved MLP model\n",
        "modelFilePath = '/content/drive/My Drive/Colab Notebooks/data/MLP_trainedModels/'\n",
        "modelFileName = 'MLP_1177_256_64_1_Adam_lr_0.001_MSELoss_bSize32_epoch5000_phyla_all_noNC_noCS_plsda_BE.pt'\n",
        "\n",
        "# Define the parameters according to the loaded model\n",
        "args = easydict.EasyDict({\n",
        "        \"feature_Num\": 1177,          # Number of features (columns) in the input data\n",
        "        \"mlp_hidden_layers_num\": 1,   # How many (middle or hidden) layers in the NN model\n",
        "        \"hidden_dim\": 256,            # Size of each hidden layer in the NN model\n",
        "        \"pre_output_layer_dim\": 64,   # Size of the layer right before the output layer in the NN model\n",
        "        \"output_dim\": 1,              # Size of the output layer\n",
        "        \"batch_size\": 32,             # Batch size\n",
        "})\n",
        "\n",
        "# Define the file to test\n",
        "testing_file = '/content/drive/My Drive/Colab Notebooks/phyla_stool_541x1177_PMI_threshold_0_clr_15p.csv'\n",
        "test_data_prefix = 'phyla_stool'\n",
        "test_data_surfix_BE_method = 'no_BE'\n",
        "\n",
        "fileNameToSave_base = (modelFileName[0:len(modelFileName)-3]+\n",
        "                                 '_vs_'+test_data_prefix+'_'+\n",
        "                                   test_data_surfix_BE_method)\n",
        "\n",
        "# Load the file of the trained model\n",
        "loadedModel = torch.load(modelFilePath+modelFileName)\n",
        "# Initiate a model object with the same architecture of the loaded model \n",
        "Model_for_Test = MLP(args.feature_Num, args.hidden_dim, \n",
        "                         args.mlp_hidden_layers_num, \n",
        "                         args.pre_output_layer_dim, args.output_dim)\n",
        "# Put the loaded model into the initiated model object\n",
        "Model_for_Test.load_state_dict(loadedModel[ 'model' ])\n",
        "\n",
        "#============================== End of Setting ================================\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaOegZh6YRnA"
      },
      "source": [
        "# sets device for model and PyTorch tensors\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class PhylaDataset(Dataset):\n",
        "    \"\"\" \n",
        "    Dataset for binary classification of IBD/Healthy\n",
        "    \"\"\"\n",
        "    # Initialize your data, download, etc.\n",
        "    def __init__(self, inputFile):\n",
        "        ori_BE_data = pd.read_csv(inputFile, low_memory=False, lineterminator='\\n')\n",
        "        phyla_BE_input = ori_BE_data[ori_BE_data.columns[1:args.feature_Num+1]]\n",
        "        phyla_BE_input = phyla_BE_input.assign(diagnosis=ori_BE_data[ori_BE_data.columns[args.feature_Num+2]])\n",
        "        phyla_BE_input = phyla_BE_input.to_numpy(dtype=np.float32)\n",
        "        self.len = phyla_BE_input.shape[0]\n",
        "        self.count_data_raw = from_numpy(phyla_BE_input[:, 0:-1])\n",
        "        self.diagnosis_data_raw = from_numpy(phyla_BE_input[:, [-1]]) # 0: Control, 1: IBD\n",
        "        self.count_data_BE = from_numpy(phyla_BE_input[:, 0:-1])\n",
        "        self.diagnosis_data_BE = from_numpy(phyla_BE_input[:, [-1]]) # 0: Control, 1: IBD\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        #return self.count_data_raw[index], self.count_data_BE[index]\n",
        "        samples = self.count_data_BE[index]\n",
        "        labels = self.diagnosis_data_BE[index]\n",
        "        return samples, labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "### Define the evaluation metric\n",
        "\n",
        "The evaluation metrics include Accuracy, Specificity, Precision, Recall, \n",
        "F1-score, and MCC.\n",
        "\n",
        "Accuracy = (TP+TN) / (TP+TN+FP+FN)\n",
        "Specificity = TN / (TN+FP)\n",
        "Recall (Sensitivity) = (TP) / (TP+FN)\n",
        "Precision = TP / (TP+FP)\n",
        "F1-score = (2*Precision*Recall) / (Precision+Recall)\n",
        "MCC = (TP*TN - FP*FN) / sqrt((TP+FN)*(TP+FP)*(TN+FN)*(TN+FP))\n",
        "\n",
        "\"\"\"\n",
        "def compute_accuracy(loader, net):\n",
        "\n",
        "    accuracy_compute_history = []\n",
        "    TP = 0\n",
        "    TN = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    with torch.no_grad():      \n",
        "        for data in loader:\n",
        "            samples, labels = data\n",
        "            outputs = net(samples)           \n",
        "            for i in range(labels.shape[0]):\n",
        "                sample_val = labels[i,0]\n",
        "                predict_val= outputs[i,0]\n",
        "                if sample_val == 1:\n",
        "                    if predict_val>0.5:\n",
        "                        TP = TP + 1\n",
        "                    else:\n",
        "                        FN = FN + 1\n",
        "                elif sample_val == 0:\n",
        "                    if predict_val <= 0.5:\n",
        "                        TN = TN + 1\n",
        "                    else:\n",
        "                        FP = FP + 1\n",
        "    if (TP+FN) != 0:\n",
        "        recall = TP/(TP+FN) # sensitivity\n",
        "    if (TN+FP) != 0:\n",
        "        specificity = TN/(TN+FP)\n",
        "    if (TP+FP) != 0:\n",
        "        precision = TP/(TP+FP)\n",
        "    if (TP+TN+FP+FN) != 0:    \n",
        "        accuracy = 100*(TP+TN)/(TP+TN+FP+FN)\n",
        "    if (precision+recall) != 0:\n",
        "        f1 = (2*precision*recall)/(precision+recall)\n",
        "    mcc = (TP*TN-FP*FN)/np.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))  # Matthews correlation coefficient\n",
        "    accuracy_compute_history.append(\n",
        "        {\"TP\": TP, \"TN\": TN, \"FP\":FP, \"FN\": FN,\n",
        "         \"Recall\":recall, \"Specificity\":specificity,\n",
        "         \"Precision\":precision, \"Accuracy\":accuracy,\n",
        "         \"F1-score\":f1, \"MCC\":mcc}\n",
        "    )\n",
        "    return accuracy_compute_history\n",
        "\n",
        "# Function of writing the testing results to a text file\n",
        "def writeResult(fileName, dataObj, modelName, testingFileName):\n",
        "    with open(fileName, 'w') as f:\n",
        "        theFirstLine = 'Model file: '+modelName+'\\n'\n",
        "        f.write(theFirstLine)\n",
        "        theSecondLine = 'Test file: '+testingFileName+'\\n'\n",
        "        f.write(theSecondLine)\n",
        "        for item in dataObj[0]:\n",
        "            strToWrite = \"{0}: {1}\\n\".format(item, np.round(dataObj[0][item], decimals=2))\n",
        "            f.write(strToWrite)\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S75ykifYeW_"
      },
      "source": [
        "\"\"\"\n",
        "Run the testing procedure\n",
        "\"\"\"\n",
        "\n",
        "# Initiate a dataloader of the testing file\n",
        "test_dataset = PhylaDataset(testing_file)\n",
        "test_loader = DataLoader(test_dataset, \n",
        "                         batch_size = args.batch_size, \n",
        "                         shuffle=True)\n",
        "\n",
        "\n",
        "# Test the loaded model\n",
        "test_dataset_metric = compute_accuracy(test_loader, Model_for_Test)\n",
        "# Save the testing metrics to a text file\n",
        "test_dataset_metric_nameToSave = resultFilePath + fileNameToSave_base + \"_test_result_metric.txt\"\n",
        "writeResult(test_dataset_metric_nameToSave, test_dataset_metric, modelFileName, testing_file)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}