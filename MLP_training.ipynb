{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDfWa+s5+Pc9wYfVJbVLIj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AikenChung/microBE/blob/main/MLP_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_qfzek4c35N"
      },
      "source": [
        "Training process for MLP model\n",
        "\n",
        "**Team: microBE**\n",
        "\n",
        "@Ali, @Anthony, @Laura, @Aiken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN6W9S3HcxLm",
        "outputId": "55bf2969-65d9-4a48-abd9-4d38fb066b07"
      },
      "source": [
        "colab = True\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from pydrive.auth import GoogleAuth \n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "import os as os\n",
        "if not os.path.exists('/content/drive/My Drive/Colab Notebooks/data'):\n",
        "    os.makedirs('/content/drive/My Drive/Colab Notebooks/data')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyMKrXSzdJTp"
      },
      "source": [
        "\n",
        "import seaborn as sns; sns.set()\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn, from_numpy, optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#progess bar\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import easydict\n",
        "\n",
        "\n",
        "if not os.path.exists('/content/drive/My Drive/Colab Notebooks/data/MLP_trainedModels'):\n",
        "    os.makedirs('/content/drive/My Drive/Colab Notebooks/data/MLP_trainedModels')\n",
        "\n",
        "if not os.path.exists('/content/drive/My Drive/Colab Notebooks/data/MLP_trainedResults'):\n",
        "    os.makedirs('/content/drive/My Drive/Colab Notebooks/data/MLP_trainedResults')\n",
        "    \n",
        "modelFilePath = '/content/drive/My Drive/Colab Notebooks/data/MLP_trainedModels/'\n",
        "resultFilePath = '/content/drive/My Drive/Colab Notebooks/data/MLP_trainedResults/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co6HlPUXdNTf"
      },
      "source": [
        "#================================== Setting ==================================\n",
        "train_base_file = 'phyla_all_noNC_noCS_4050x1177_PMI_threshold_0_clr_plsda_85p.csv'\n",
        "#train_base_file_url = 'https://drive.google.com/file/d/1BxK876BrT1aT2xVUaHafwiqBNxYw5bBn/view?usp=sharing'\n",
        "train_data_prefix = 'phyla_all_noNC_noCS'\n",
        "train_data_surfix_BE_method = 'plsda_BE'\n",
        "\n",
        "args = easydict.EasyDict({\n",
        "        \"feature_Num\": 1177,        # Number of features (columns) in the input data\n",
        "        \"epochs\": 5000,             # Number of iterations to train Model for\n",
        "        \"hidden_dim\": 256,          # Size of each hidden layer in Discriminator\n",
        "        \"pre_output_layer_dim\": 64, # Size of each hidden layer in Discriminator\n",
        "        \"output_dim\": 1,            # Size of output layer\n",
        "        \"mlp_hidden_layers_num\": 1, # How many (middle or hidden) layers in Discriminator (ie. 'mlp':  w/o 1st & last; 'resnet's: num. resudual blocks)\n",
        "        \"batch_size\": 32,           # Batch size\n",
        "        \"learning_rate\": 0.001,     # Learning rate for the optimizer\n",
        "        \"beta1\": 0.5,               # 'beta1' for the optimizer\n",
        "        \"adapt_lr_iters\": 5,        # how often decrease the learning rate\n",
        "})\n",
        "\n",
        "\n",
        "fileNameToSave_base = ('MLP_'+ str(args.feature_Num) +'_'+ \n",
        "                               str(args.hidden_dim) + '_' + \n",
        "                               str(args.pre_output_layer_dim) + '_' +\n",
        "                               str(args.output_dim) + '_Adam_lr_'+\n",
        "                               str(args.learning_rate) + '_MSELoss_bSize'+\n",
        "                               str(args.batch_size) + '_epoch'+\n",
        "                               str(args.epochs) + '_'+train_data_prefix+'_'+\n",
        "                               train_data_surfix_BE_method)\n",
        "\n",
        "\n",
        "#============================== End of Setting ================================"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlqlNJYeteSA",
        "outputId": "7bc13ec9-b667-4173-8b6d-d2acc1d6a58d"
      },
      "source": [
        "\n",
        "import logging\n",
        "logging.getLogger('googleapiclient.discovery_cache').setLevel(logging.ERROR)\n",
        "\n",
        "file_list = drive.ListFile({'q': \"'1aUlG3KemS6u9qKI3nT-4XEmWFNVQR3i_' in parents and trashed=false\"}).GetList()\n",
        "for file1 in file_list:\n",
        "  print('title: %s, id: %s' % (file1['title'], file1['id']))\n",
        "\n",
        "data_downloaded = drive.CreateFile({'id': '1BxK876BrT1aT2xVUaHafwiqBNxYw5bBn'})\n",
        "data_downloaded.GetContentFile('phyla_all_noNC_noCS_4050x1177_PMI_threshold_0_clr_plsda_85p.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: MLP_training.ipynb, id: 1ZRZq0htufNRxJz8EEcrkcZYu8wvWi6EB\n",
            "title: data, id: 1-59EAqGGegW1WhPFgus9El9XyiDes6DM\n",
            "title: phyla_all_noNC_noCS_4050x1177_PMI_threshold_0_clr_plsda_85p.csv, id: 1BxK876BrT1aT2xVUaHafwiqBNxYw5bBn\n",
            "title: remote_SSH, id: 1d3_MsesxaLvZJg_v8L_3vdXTtllD2dX3\n",
            "title: preprocessing_Dev, id: 1qo_mUWL0bWJh7Xq8zg5w4vH7skGeL8Mu\n",
            "title: csvData, id: 1jFPVCcbL3ln7w1U-GUU4TWi9aCq2UMot\n",
            "title: AI_in_Genomics_Assignments, id: 12vJGH4NHRDLyb7BYazjHJadCliupBVmq\n",
            "title: phylaMLP.ipynb, id: 1WLwiwSJgUMW7C0DjLtxRSvoniSbbZ13t\n",
            "title: NN_Classifier_LoadAndTest.ipynb, id: 1PFB2F2jPkZoQZgYyBdxuSzKiRGfHUrvK\n",
            "title: phyla_data_PCA_UMAP.ipynb, id: 1OchVuECizQB7q0F3ZYRcmYlL-Ovka2UM\n",
            "title: phyla_all_4514x1177_PMI_threshold_0_clr_plsda_85p.csv, id: 1ezFV1Yrb6mGCE965I3R_3_VYdjDMH28L\n",
            "title: phyla_biopsy_noCS_1252x1177_PMI_threshold_0_clr_plsda_85p.csv, id: 12nuz96KhOZqCOe8cjC-68_gxwdOY80ib\n",
            "title: phyla_biopsy_1273x1177_PMI_threshold_0_clr_plsda_85p.csv, id: 18pJf8SuGlUmgMp5ii2hHPpSG2VCDtNQS\n",
            "title: phyla_stool_3240x1177_PMI_threshold_0_clr_plsda_85p.csv, id: 1Hngs8sdNYzVT_8bu7mHq_l7GsrUsMZis\n",
            "title: phyla_stool_noNC_2798x1177_PMI_threshold_0_clr_plsda_85p.csv, id: 1QT5g5oF-yqRmWgn2Z9vykYM8b8EZvt55\n",
            "title: phyla_stool_noNC_3265x1177_PMI_threshold_0_clr_plsda.csv, id: 1PKfpuB44MZleSoz9gB_yGOa7eW5xqpw1\n",
            "title: phyla_data_preprocessing_PMI_CLR_limma.ipynb, id: 1EccSO8cMMzkqoSXldeC1mQIdZDIhz043\n",
            "title: NormAE, id: 1QIZoDaozA7iJYvxVen6fJJ-r1IXO-yWl\n",
            "title: CodeFile, id: 1QVK6_SByVZMrnVcQGx-L0p2IamMOv550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boO3FoJtjOcs"
      },
      "source": [
        "\n",
        "# sets device for model and PyTorch url)tensors\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class PhylaDataset(Dataset):\n",
        "    \"\"\" Phyla dataset\"\"\"\n",
        "    \"\"\"\n",
        "    Dataset for binary classification IBD/Healthy\n",
        "    \"\"\"\n",
        "    # Initialize your data, download, etc.\n",
        "    def __init__(self, inputFile):\n",
        "        ori_data = pd.read_csv(inputFile, low_memory=False, lineterminator='\\n')\n",
        "        phyla_input = ori_data[ori_data.columns[1:args.feature_Num+1]]\n",
        "        phyla_input = phyla_input.assign(diagnosis=ori_data[ori_data.columns[args.feature_Num+2]])\n",
        "        phyla_input = phyla_input.to_numpy(dtype=np.float32)\n",
        "        self.len = phyla_input.shape[0]\n",
        "        self.count_data = from_numpy(phyla_input[:, 0:-1])\n",
        "        self.diagnosis_data = from_numpy(phyla_input[:, [-1]]) # 0: Control, 1: IBD\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        samples = self.count_data[index]\n",
        "        labels = self.diagnosis_data[index]\n",
        "        return samples, labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Preparing data for training and validaing\n",
        "\"\"\"\n",
        "\n",
        "dataset = PhylaDataset(train_base_file) \n",
        "num_cohorts, num_genus = dataset.count_data.shape\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INds_WZ-dpRZ"
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "We now need to split our dataset into two parts.\n",
        "The **train set** will be used to train our model, and the **test set** will be used for evaluation.\n",
        "First, let us compute the number of samples to put in each split. \n",
        "Here we choose to keep 80\\% of the samples for training and 20\\% for testing\n",
        "\"\"\"\n",
        "\n",
        "# starting time\n",
        "start = time.time()\n",
        "\n",
        "train_set_size = int(len(dataset) * 0.8)\n",
        "validate_set_size = len(dataset) - train_set_size\n",
        "\n",
        "\"\"\"Split randomly our dataset into two parts\"\"\"\n",
        "\n",
        "train_dataset, validate_dataset = torch.utils.data.random_split(dataset, \n",
        "                                                            lengths=[train_set_size, validate_set_size], \n",
        "                                                            generator=torch.Generator().manual_seed(0))\n",
        "\n",
        "\"\"\"\n",
        "We initialize dataloader objects. \n",
        "These dataloaders will provide data one batch at a time, \n",
        "which is convenient to train our machine learning model.\n",
        "\"\"\"\n",
        "\n",
        "train_loader = DataLoader(train_dataset, \n",
        "                                           batch_size = args.batch_size, \n",
        "                                           shuffle=True)\n",
        "validate_loader = DataLoader(validate_dataset, \n",
        "                                          batch_size = args.batch_size, \n",
        "                                          shuffle=True)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\" Multi-Layer Perceptron for classifying IBD and Healthy microbiome data\"\"\"\n",
        "    def __init__(self, input_dim=1177, hidden_dim=256, \n",
        "                 hidden_layer_num=1, \n",
        "                 pre_output_dim = 64, \n",
        "                 output_dim=1):        \n",
        "        super(MLP, self).__init__()        \n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(nn.Linear(input_dim, hidden_dim))\n",
        "        for layer in range(hidden_layer_num):\n",
        "            self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "        self.layers.append(nn.Linear(hidden_dim, pre_output_dim))\n",
        "        self.layers.append(nn.Linear(pre_output_dim, output_dim))\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = torch.tanh(layer(x))\n",
        "        out = self.layers[-1](x)\n",
        "        out = torch.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "def training(model, loader, optimizer, criterion, device):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(loader,0):\n",
        "      # get the inputs; data is a list of [samples, labels]\n",
        "      samples, labels = data\n",
        "      \n",
        "      # into the defined NN model in that device.\n",
        "      samples = samples.to(device)\n",
        "      labels = labels.to(device)\n",
        "      \n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # forward + backward + optimize\n",
        "      outputs = model(samples)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.to(device)\n",
        "      loss.backward()\n",
        "      optimizer.step()  # Update the parameters of the model\n",
        "          \n",
        "      running_loss += loss.item()         \n",
        "      return running_loss/len(loader)\n",
        "       \n",
        "    print('Finished Training')\n",
        "\n",
        "\n",
        "def validating(model, data_loader, criterion, device):\n",
        "\n",
        "  with torch.no_grad():\n",
        "    pass_loss = 0.0\n",
        "    for samples, labels in data_loader:\n",
        "        samples = samples.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(samples)\n",
        "        loss = criterion(outputs, labels)\n",
        "        pass_loss += loss.item()\n",
        "    \n",
        "    return pass_loss/len(data_loader)\n",
        "\n",
        "\n",
        "def run_training_process(model, nb_epochs, train_loader, validate_loader, optimizer, scheduler, criterion, fileNameForModel, device ):\n",
        "  #Subjecting the define NN model to the device which can be CPU or GPU\n",
        "  model = model.to(device)\n",
        "  progress_bar = tqdm(range(nb_epochs), position=0, leave=True)\n",
        "  loss_history = []\n",
        "  for epoch in progress_bar:\n",
        "      train_loss = training(model, train_loader, optimizer, criterion, device)\n",
        "      test_loss = validating(model, validate_loader, criterion, device)\n",
        "      loss_history.append(\n",
        "          {\"loss\": train_loss, \"set\": \"train\", \"epochs\": epoch}\n",
        "      )\n",
        "      loss_history.append(\n",
        "          {\"loss\": test_loss, \"set\": \"validate\", \"epochs\": epoch}\n",
        "      )\n",
        "      # save models during each training iteration\n",
        "      checkpoint = {'model' : model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
        "      fileNameToSave = fileNameForModel + \".pt\"\n",
        "      if epoch % args.adapt_lr_iters == 0 :\n",
        "          save_model(checkpoint,fileNameToSave)\n",
        "          # Using scheduler to update the learning rate every 100 iterations.\n",
        "          scheduler.step()\n",
        "  return pd.DataFrame(loss_history)\n",
        "\n",
        "\n",
        "def save_model(model_state, fileName):\n",
        "    #print(\"=> Saving model\")\n",
        "    torch.save(model_state,fileName)\n",
        "\n",
        "\"\"\" \n",
        "Define the evaluation metric:\n",
        "\n",
        "We will use several evaluation metrics.\n",
        "Accuracy = (TP+TN) / (TP+TN+FP+FN)\n",
        "Specificity = TN / (TN+FP)\n",
        "Recall (Sensitivity) = (TP) / (TP+FN)\n",
        "Precision = TP / (TP+FP)\n",
        "F1-score = (2*Precision*Recall) / (Precision+Recall)\n",
        "MCC = (TP*TN - FP*FN) / sqrt((TP+FN)*(TP+FP)*(TN+FN)*(TN+FP))\n",
        "\"\"\"\n",
        "\n",
        "def compute_accuracy(loader, net):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    accuracy_compute_history = []\n",
        "    TP = 0\n",
        "    TN = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    with torch.no_grad():      \n",
        "        for data in loader:\n",
        "            samples, labels = data\n",
        "            samples = samples.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = net(samples)           \n",
        "            for i in range(labels.shape[0]):\n",
        "                sample_val = labels[i,0]\n",
        "                predict_val= outputs[i,0]\n",
        "                if sample_val == 1:\n",
        "                    if predict_val>0.5:\n",
        "                        TP = TP + 1\n",
        "                    else:\n",
        "                        FN = FN + 1\n",
        "                elif sample_val == 0:\n",
        "                    if predict_val <= 0.5:\n",
        "                        TN = TN + 1\n",
        "                    else:\n",
        "                        FP = FP + 1\n",
        "    if (TP+FN) != 0:\n",
        "        recall = TP/(TP+FN) # sensitivity\n",
        "    if (TN+FP) != 0:\n",
        "        specificity = TN/(TN+FP)\n",
        "    if (TP+FP) != 0:\n",
        "        precision = TP/(TP+FP)\n",
        "    if (TP+TN+FP+FN) != 0:    \n",
        "        accuracy = 100*(TP+TN)/(TP+TN+FP+FN)\n",
        "    if (precision+recall) != 0:\n",
        "        f1 = (2*precision*recall)/(precision+recall)\n",
        "    mcc = (TP*TN-FP*FN)/np.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))  # Matthews correlation coefficient\n",
        "    accuracy_compute_history.append(\n",
        "        {\"TP\": TP, \"TN\": TN, \"FP\":FP, \"FN\": FN,\n",
        "         \"Recall\":recall, \"Specificity\":specificity,\n",
        "         \"Precision\":precision, \"Accuracy\":accuracy,\n",
        "         \"F1-score\":f1, \"MCC\":mcc}\n",
        "    )\n",
        "    return accuracy_compute_history\n",
        "\n",
        "def writeResult(fileName, dataObj, modelName, testingFileName):\n",
        "    with open(fileName, 'w') as f:\n",
        "        theFirstLine = 'Model file: '+modelName+'\\n'\n",
        "        f.write(theFirstLine)\n",
        "        theSecondLine = 'Test file: '+testingFileName+'\\n'\n",
        "        f.write(theSecondLine)\n",
        "        for item in dataObj[0]:\n",
        "            strToWrite = \"{0}: {1}\\n\".format(item, np.round(dataObj[0][item], decimals=2))\n",
        "            f.write(strToWrite)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSDplLPzd--y",
        "outputId": "8acd5815-ea43-4612-ecf4-6bb011ece311"
      },
      "source": [
        "\"\"\"\n",
        "Start to train the MLP model\n",
        "\"\"\"\n",
        "# Initilize model, criterion, optimizer. Then train the model\n",
        "classifierMLP = MLP(args.feature_Num, args.hidden_dim, \n",
        "                         args.mlp_hidden_layers_num, \n",
        "                         args.pre_output_layer_dim, args.output_dim)\n",
        "\n",
        "# cost function (for predicting labels)\n",
        "#criterion = torch.nn.CrossEntropyLoss()\n",
        "#criterion = nn.BCELoss()\n",
        "#criterion = nn.BCEWithLogitsLoss()\n",
        "criterion = nn.MSELoss(reduction='sum')\n",
        "\n",
        "# setup optimizer\n",
        "optimizer_mlp = optim.Adam(list(classifierMLP.parameters()), lr=args.learning_rate, betas=(args.beta1, 0.999))\n",
        "# use an exponentially decaying learning rate\n",
        "scheduler_mlp= optim.lr_scheduler.ExponentialLR(optimizer_mlp, gamma=0.99)\n",
        "\n",
        "modelNameToSave = modelFilePath + fileNameToSave_base\n",
        "training_history = run_training_process(classifierMLP, args.epochs, train_loader, validate_loader, optimizer_mlp, scheduler_mlp, criterion, modelNameToSave, device=device )\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [03:44<00:00, 22.28it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "gzaz55wLzOkq",
        "outputId": "978d80b1-eb01-4d8c-cb0a-e3d083d9e549"
      },
      "source": [
        "train_dataset_metric = compute_accuracy(train_loader, classifierMLP)\n",
        "train_dataset_metric_nameToSave = resultFilePath + fileNameToSave_base + \"_train_result_metric.txt\"\n",
        "validation_dataset_metric = compute_accuracy(validate_loader, classifierMLP)\n",
        "validation_dataset_metric_nameToSave = resultFilePath + fileNameToSave_base + \"_validation_result_metric.txt\"\n",
        "\n",
        "writeResult(train_dataset_metric_nameToSave, train_dataset_metric, fileNameToSave_base, train_base_file)\n",
        "validationFileName = train_base_file[0:len(train_base_file)-4]+\"_validation\"\n",
        "writeResult(validation_dataset_metric_nameToSave, validation_dataset_metric, fileNameToSave_base, validationFileName)\n",
        "        \n",
        "print('Accuracy of the MLP on the ' + str(len(train_dataset)) + ' train samples: %d %%' % train_dataset_metric[0][\"Accuracy\"])\n",
        "\n",
        "print('Accuracy of the MLP on the ' + str(len(validate_dataset)) + ' validation samples: %d %%' % validation_dataset_metric[0][\"Accuracy\"])\n",
        "\n",
        "training_history.head()\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.lineplot(x=\"epochs\", y=\"loss\", hue= \"set\", data=training_history)\n",
        "fig_trainHistory = ax.get_figure()\n",
        "training_history_plotName = resultFilePath + fileNameToSave_base +'_training_history.png'\n",
        "fig_trainHistory.savefig(training_history_plotName)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the MLP on the 3240 train samples: 98 %\n",
            "Accuracy of the MLP on the 810 validation samples: 89 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEMCAYAAADDMN02AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU1cEG8PfeO1smOyGEQEAEDTsioKiAShBBqCxqteUTF7B8FXAptUUFF/ikGkSrLEIRWlxrtRQQRMVKrUAFARGKiiAiYcmeQDJJZrn3nu+PSYYsk2SyzCSZ+/6eh4eZu51zZibvnDlz51xJCCFARESGIbd0BYiIKLQY/EREBsPgJyIyGAY/EZHBMPiJiAyGwU9EZDAMfiIigzG1dAUCVVhYAl1v+E8OEhKikJ/vCEKNWi+22RiM1majtRdoWptlWUJ8fKTfdW0m+HVdNCr4K/Y1GrbZGIzWZqO1FwhOmznUQ0RkMCHp8Z8+fRqzZs3y3S8uLobD4cCXX34ZiuKJiKiSkAR/SkoKNm3a5Lu/aNEiaJoWiqKJqBUSQqCwMBdutxNAYEMZOTkydF0PbsVamfrbLMFisSE+PhGSJAV83JCP8bvdbmzevBlr164NddFE1Eo4HOchSRKSklIgSYGNOJtMMlTVWMFfX5uF0HHuXB4cjvOIjo4L+LghH+Pfvn07kpKS0Ldv31AXTUStRFmZA9HRcQGHPvknSTKio+NRVtawM39C3uNfv349br311gbvl5AQ1egyExOjG71vW8U2G0NbbXNOjoDVamnQ8ATg7QEbTX1tVhQLANGg10JIgz87Oxt79+7F4sWLG7xvfr6jwac1lf1rNaI7XQS155gGl9eWJSZGIze3uKWrEVJsc9ui6zo0TSDQ8X2AQz110XW9xmtBlqVaO8whDf4NGzbguuuuQ3x8fEjK0/N+glsRkHuGpDgiojYhpJ+bNmzY0KhhnqYx3g8+iCg4MjPPYvjwIVBVtaWr0iQh7fF//PHHoSwOQMPGD4mIjCDsvynhJYWJqDZvvrkOkybdhNGjr8Uvf3kL9u37Erqu44031uH22ydi3LhReOKJR1FUdB4AMGvWrwAAN900EqNHj8Dhw4dasvqN1mbm6mkc9viJyL+MjJ/wj3+8hzVrXkf79onIzDwLXdfx97//DTt2fIbly1cjLi4eL730PF54IR0LFvwBK1a8ip//fAI+/PBfMJnabnyGd4+fuU9EtZBlBW63GydO/AhVVZGc3AmdO6dg06b1mDFjJjp0SILFYsG0af+Lzz77tM2P61fWdt+yAsWhHiLyIyWlCx588Lf4859X48SJHzF06FV44IE5yMrKxOOP/w6yfKHnqCgKCgsLWrC2zSvMg59dfiKq3Y03jsWNN45FSYkDixf/AStXLkWHDkl47LEnMWDAwBrbZ2VltkAtm194D/UA4OmcRORPRsZP2L9/L9xuNywWK6xWKyRJxqRJt2L16ld8IV9YWIgdOz4DAMTFxUOWZZw9e6YFa9504d3jZ4efiGrhdnuwatUy/PTTTzCZTOjffwB+//t5aNcuAUII/OY3s5CXl4f4+HiMGnUjRoy4HjabDXfdNQ0zZ06HqqpYsmQZ+vXr39JNaTBJtJHzHRszZUPJ+idga9cRyshZ9W8cRtryT/kbi21uW7KyTqJjx4satA+nbKidv8ezrikbwnyoRwKHeoiIqjJA8BMRUWVhHvzg6ZxERNWEd/Czw09EVEN4Bz8REdUQ5sHPLj8RUXVhHvycnZOIqLrwDn6Jp3MSEVUX3sFPRBSAtWv/BI/H0+D9jhz5FgsWzA9CjYIr/IOfHX4iqsdf/vKq3+CvbyrmXr364KmnnglWtYImvOfq4Ze7RK3erv9mYueh+me9lKSG/yxn+IBkDOufXOc2L7yQDgC4//5pkCQZycnJiI2NQ0bGSZSWlmLdurexYMF8ZGSchMfjRufOXfDYY08iJiYGX321DytWvIy1a99AZuZZ3HffVEyYcAt2794Fp9OJRx99EpddVnOWz5YWsh6/y+XCU089hRtvvBE333wznnjiiRCVzC4/EdXut7+dCwBYufLPWLfubURFRePYsaN44YVlWLfubQDAQw89grVr38Drr/8NF1/cHW+99ZrfY50/fx79+g3AX/7yNu6991dYtWppyNrRECHr8T///POwWq34+OOPIUkS8vLygl+oBDD4iVq3Yf3r75UDoZ2k7frrRyEiIsJ3/6OPtmDbto+gqh6UlTnRpUtXv/tFRNgxbNgIAEDfvv2xfPlLIalvQ4Uk+EtKSrBx40b8+9//hiR5h1/at28fgpI51ENEDWe3Xwj9gwcPYOPG9Vi58s+Ij4/Htm0f4f33/+F3P4vF7LstyzI0rXVerjEkQz2nTp1CXFwcli9fjltuuQVTp07Fvn37QlE0O/xEVC+7PRIlJQ6/64qLixEZGYXY2Fi43W588MH7Ia5d8wtJj1/TNJw6dQp9+vTB3LlzcfDgQfz617/GJ598gqgo//NFV1fbvNJ1cZu9zUtMjG7wvm0d22wMbbXNOTkyTKaG9zsbs08gpky5Ew89dD+sViuSkztBliVfWcOHD8Mnn3yIKVNuQWxsHAYOHIRvv/0GJpMMRZEhSfDdBi7sV/1+YwWyvyzLDXothORCLAUFBRgxYgQOHz7sG+oZN24c0tPT0b9/YFevadSFWDY9A6vdDtPoOQ2uc1vWli/Q0Vhsc9vCC7EEpk1fiKVdu3YYOnQodu3aBQA4ceIE8vPzcdFFDXviiYio6UJ2Vs+CBQvw+OOPIz09HSaTCYsXL0ZMTEzwC+ZcPUREVYQs+Lt06YI33ngjVMUBACRI/G6XiKia8J6yQeLpnERE1YV38AMc6iEiqib8g5+IiKowQPCzx09EzWv27BnYtWsHAGDNmlX49NNtfrdbu/ZPAU3bsHXrZmRknGzWOtYlvGfn5Bg/EQXZfff9usnH2Lp1M2Jj49C1a2hOcQ/v4AfY4SeiOq1btwZFRefx4IO/BQCcP38OU6bcinnzFuC119bC7XZB0zTcddc03HDDmBr7L1r0NHr16o1bb70DDocDzz23ED/+eBzt2iUgKSkJ8fEJAIB9+77Eq6+urHG8Dz54H99//x1eemkJXn11JWbNeghXXDEUb765Dp9//i+oqor27Ttg7tx5SEhonjnOwj/4mfxErZrn6C54vv+83u0kSWrwNbTNPa+FOXVYnduMHfsz/O//3o2ZMx+CyWTCJ598hGHDrkW/fgPwyitroCgKCgryMX36VFx55dV1/v7oL395FXZ7JN5+ez3OnTuHadP+B2lpowEAqam9/B5v/PgJ+PDDLfjlL6f6Zvb8+OOtOHPmDNaseQ26DmzY8HcsX/5Ss130JcyDn0M9RFS3jh07olu3Hti9exeGD78OW7duwYMPzsG5c4V49tmFOH06A4piQlHReWRknES/frVPM3PgwD48/PDvAABxcXG47ro037qGHG/nzs9x5Mh3uPvuKRAC0DQ14HnNAhHmwQ+ezknUyplTh9XbKweCO1fPuHE/w4cfbkFycmeUlDhw2WWX4+GHZ2LYsGvxhz88D0mS8Itf3AK329XoMl544bmAjyeEwN13T8OkSZOD0ubwPquHX+4SUQCuuy4NBw8ewDvvvImbbvoZJElCcXExkpOTIUkS9u7djTNnTtV7nEGDrsDWrZsBeL8r+Pzzf/nW1XW8yMiq00IPH34tNmz4O4qKigAAbrcbx44dba7mGqDHT0RUD5vNVj7Msxnvvuudb//++2fjhRfSsXbtavTu3Qc9elxa73Huuec+PPvsAkyZcivatUvAwIGX+9bVdbwJE27B8uV/xNtvv4FZsx7C2LHjcf78Odx//30AAF3XMXnyz3HppanN0t6QTMvcHBozLXPplnSYFcB809wg1ap1asvT9TYW29y2cFrmwLTpaZlbUht5XyMiCpnwDn5JAk/nJCKqKryDn6dzEhHVEObBD3b4iVopDsM2j8Y8juEf/ETU6phMFpSUFDH8m0gIgZKSIphMlgbtZ4DTOfnCImpt4uMTUViYC4fjXMD7yLIMXTfWWT2BtNlksiA+PrFBxw3v4JckoIGngBJR8CmKCe3bJzdon7Z8+mpjBavNHOohIjKYkPX409LSYLFYYLVaAQCPPPIIRowYEariiYioXEiHepYuXYrU1Ob5yXFAOFcPEVEN4T/Uw7MGiIiqCGmP/5FHHoEQAoMHD8acOXPqvKBB82CPn4ioupBN0paZmYnk5GS43W4sWrQIJSUlWLJkSXDLfOcZ6KVF6DxtcVDLISJqS0LW409O9p66ZbFYMGXKFNx///0N2r8xs3O63RoUAZ4CZgBsc/gzWnuBprW5xWfnLC0tRXGxt/JCCGzduhW9e/cOfsH8cpeIqIaQ9Pjz8/PxwAMPQNM06LqOHj164KmnngpF0eAvd4mIqgpJ8Hfp0gUbN24MRVFERFQPns5JRGQwYR78HOMnIqouzIOfiIiqC+vglySJQz1ERNWEdfATEVFNBgh+9viJiCoL7+DnD7iIiGoI7+AHwB4/EVFVYR78Er/bJSKqJsyDn4iIqjNA8LPLT0RUWXgHP7/cJSKqIbyDH+APuIiIqgn/4CcioioY/EREBhPewc+5eoiIagjv4Oe0zERENYR58AM8nZOIqCoDBD8REVUW/sHPDj8RURUhD/7ly5ejZ8+eOHr0aPAL4w+4iIhqCGnwf/PNN/j666/RuXPnEJbKLj8RUWUhC363242FCxfi6aefDlWR8M7OyeAnIqrMFKqCXn75ZUyYMAEpKSmN2j8hIarB++TYzHACSEyMblSZbRnbbAxGa7PR2gsEp80hCf4DBw7g8OHDeOSRRxp9jPx8B3S9Yb13p8sDAMjNLW50uW1RYmI022wARmuz0doLNK3NsizV2mEOyVDP3r17cfz4cYwaNQppaWnIysrC9OnTsXPnziCXzC93iYiqC0mPf8aMGZgxY4bvflpaGlatWoXU1NTgF84xfiKiKsL/PH4iIqoiZF/uVrZ9+/YQlsYePxFRZeHd45ck5j4RUTXhHfz8cpeIqIaAg3/37t04deoUACAnJwdz587FY489htzc3KBVrnmwy09EVFnAwb9gwQIoigIASE9Ph6qqkCQJTzzxRNAq12Ts8BMR1RDwl7vZ2dno1KkTVFXFzp07sX37dpjNZowYMSKY9Ws6ns5JRFRFwMEfFRWFvLw8HDt2DD169EBkZCTcbjdUVQ1m/ZpI4kAPEVE1AQf/nXfeidtuuw0ejwePP/44AOCrr75C9+7dg1a5puNYDxFRdQEH/4wZMzB69GgoioKuXbsCAJKSkvDMM88ErXLNgkM9RERVNOgHXBdffLHv9u7duyHLMq688spmr1Rz4Wn8REQ1BXxWz5133on9+/cDAFavXo05c+bgt7/9LVatWhW0yjUPRj8RUWUBB/+xY8cwcOBAAMB7772H119/He+++y7eeeedoFWu6TjGT0RUXcBDPbquQ5IkZGRkQAiBSy65BABw/vz5oFWuWbDDT0RURcDBP3jwYCxcuBC5ubkYPXo0ACAjIwPx8fFBq1yTSQCTn4ioqoCHep599lnExMSgZ8+emD17NgDgxx9/xF133RW0yjUdh3qIiKoLuMcfHx+POXPmVFl2/fXXN3d9mh9P5yQiqiLgHr/H48HSpUsxatQo9O/fH6NGjcLSpUvhdruDWb8mYo+fiKi6gHv8zz//PA4dOoQFCxagU6dOOHv2LF555RU4HA7fL3mJiKj1Czj4P/roI2zatMn3ZW737t3Rp08fTJw4sfUGPzv8REQ1BDzUI2oZK69teesgQQi9pStBRNSqBNzjHzt2LO6//37MmjULnTp1wpkzZ7By5UqMHTs2oP1nzpyJ06dPQ5Zl2O12PPHEE+jdu3ejKx4QSeaXu0RE1QQc/L/73e+wcuVKLFy4EDk5OUhKSsK4ceMwc+bMgPZPT09HdHQ0AOCf//wnHn/8cWzYsKFxtQ6UJAFCQD19GFrWMVj63whRVgQ5Ljm45RIRtWJ1Bv8XX3xR5f6VV15ZY1K2/fv34+qrr663oIrQBwCHwwFJCsEAvCQBQkfZ1iUAAM8PuyGKshE9Y13wyyYiaqXqDP558+b5XV4R2kIISJKETz/9NKDC5s2bh127dkEIgTVr1jSwqg0n3E7ortIL94uyg14mEVFrJ4kW+HZ248aN+OCDD/Dqq68GtZyzbzwBZ8a3NZZ3n7c+qOUSEbVmDZqPv7lMmjQJTz75JAoLCwOe6yc/3wFdb9h7lEf1v31ubnGDjtPWJCZGh30bq2Obw5/R2gs0rc2yLCEhIcr/uqZUKlAlJSXIzMz03d++fTtiY2MRFxcX3IKlkDSPiKhNCUmPv6ysDA899BDKysogyzJiY2OxatWq4H/Bq3nq3cTz/Q5IEdEwdR0Y3LoQEbUSIQn+9u3b49133w1FUVVoWUfr3cb577UAwDN9molwlQBCQLL5/4ip5Z6AXpwHU+c+0HKOQ4pKgPvrrRBFObBdPx1ybEe/x3Qf/BCw2GHuORxyRMyFdUKg8tTbwuOE64u3oeWfgp57AqZLrobSoTvk+M6ApgKKCWrGQchRCZDbXwS98Az0wjNQOveFKM6DcJVAjkv2/h/fCVJEDITTAeFyQIIMyR4LmK2AxwnhdkKOSYReUgj15NcABCRZge7Ih2SJ9J5VBgHJGgXJageEDlE+XClJgHCXQXhcEC6Ht26yAggB4XECrhII1Qlo2oUHQqp8Q4LTJEPzqN6DSTJgMgOSDEk2lZeNC596Jal8meRbJ8kKIJsAxVz+mxe9/J+ocVtULKvMb8dNqrTaz3rfsrrW+V+ebTXD5VLr2KcxHck6ho8b/fVn831tWti5O9D7pmY7XoUWGeOn5qE7i1H24YuIuGEm5OjElq4OhKbC8dosAEDk1KUQxbnQC8/ClDoc2qlDEJoK5yfLat2/5G+PAgCUTr2hZR2DHJcMveBUlW3c+/4ByR4LS/8xkBO7wb1/E/TCM8ju2hslRy6cfqwk94Rkj4P6wxdQf6h6WrI/nm8COzOtVhVhq+uQIuMg3GWVKl2GWsPAbINkjYSkmCF0DZBlSCYLJGsUZFt775tB+e9RqhACZqsJwq1dCGfVfSGwdW9oC4jyfcWFYwi9/K4GoamAWj7RYsUbSPn/UqXbF5ZLvvLLb1SqU5UKlt/1t76eZbWsdysydE33lV31EakrwFHPe0LtK+vera61zTOa4baagzIez+Bvw9Qf9kDPPQH3oY9gGza1yjr9XCZgjazSO24oreA0IMtQ4jrVuZ3QPFAzDsL5yXLfspI3HrywQfmnKn+UpEuhJKdCskbBtedv3nLPfgcpIsbbgwUAxQTbsLsgRbeH+9BH0E4dguuLt6scp+TIF4BihtIxFebUYTBfeo1vnV6cB70ox9uzVV2QItsBmhu6owCSyQI5rhN0Rz7kmERIJgv08zmQzFbo57IgVBckW5T3E4yuQ5Sdh/C4IJltgMkC4cgHJBmmi4cAJgsgdG9PuvLjo6uAx3UhQL1LAcVcY9uGMNqXnUZrLxC8NjP427SKXk7N3kXJu48BJguip60O+GjOnW/A88MXiL7nFQBA6d/nAwBsI2dAssdBjm4PveAMIMuQ218E2R4HIQRKNz4DPf+k9yCKBeZLr4HnyGc1ji9FxMJ65W0w9xwBLedHyHEdIVnsvvWm7ldAPX0Ypi79IUW2gyRJvt+K+Lbp3AdC6NDOHoFwOaC06wKhuhEXa0OxOclvu+To9pCj29dYrrTvdmGbqHYXlid6lzfqF95SzSCXZBNg5Z8atR58NbYgoalw/edNWAZPgmxvxBlO5R959cIzcH+7HaaUfpBjOlxYrwZ2rQSh64Dqgudb73BHyaZnoGf/4Fvv/Jf/Nw8puj1EcZ7vvty+GyJumAU5JhG2a+8pr6IANA8kk6XKvkqH7jWOJ0e3h6X39VXL8PNxWpJkmDr3qbLMlhiNYoP1Bokai8EfRELX4drzN1guu8lvsKsZX8Pz3WcQTgciRs9u0LG1wrMQZd4L3Wtnv4N29ju4UPNLaucXf4V+PguiKBfmAWMA1QP19H9hHTQRpRsX+j125dCvs33loW/qNgi2tF/XCHegPLj9LCeilhPWwW+58udwf/lereuFxxnU8rWs7+H578fQC8/APu4R77L8U/Ac+QzWa/7H12NXT+yD0HVIcuBf45S+5/8aCEIIlHy/x3ff89+Pfbddn//lwv4ZB/3ub5/0BPSiXEi2KIjSc3B+tgamHlfBNnIGIEnQznzjHUtvlwL34U9g7nUd5MjAfoRHRK1DWAd/bcMnQghoGV+j7OOXg1wB78Nb8QZTvPoe3yrLZeOqnBWg/vglzJdcFdBhq5wxUo1+7iyy/7444Cpar/kfuA9uhXXILTBdOgySLEPp0MO33pw6vMr2ppR+F/YdPCngcoio9Qjvn7bWcsaE858r4Dn+ZUCHULOOwXNin991wl3qPWMDgF56zns6XiWSUv6+qqk11kHXUPlLWaG6LtwWwndc57//jNIPX6yyq2Pd/bXWt/Q9/xPrRYx52HfbPODCNRQs/UYjcsqLMPcc0aBPHETUdoV1j7+2KRvUWoLcn7L3FwEAzH5+4OVYNxOmboNhHX4XSt58GKbUEYi4fjoAby9fLynw3i7OQ1m18BaaWvU84Ipzk4WAa9cb8Hy7HVHT18Dz/ecB19Uf67X3QrLYYbpoIKKmr4EoKYAUGQ9T575QUvoCqOWHNkQUtsI6+JWkSxq0vZZ3Es7tf4L16l9AimwHpV1KvfuoP+33/poTgHp0B1Ae/KVbl/i+JBUuh3dsvEphbu8PZCqOc+w/cO1YV2UTUf7GAQClHzwP3ZEX0K8Jze1TYJ20ANBVSCarb7mkmCCVn/Vj6tK/3uMQUXgK6+CvfG52IDzffAr93Flf77z6GTJq1lHo5zJh7n4FHOsuXHlMqBfmBKroydd3ZoyW+X2V6Qn8TS9R8s7vL6yv9sZh7nU9bNfeA9fe9ZAsEZATL0bZlnQoXfojZeqTyMsrqXWoi4iMLayDv6EqxtVrU/b+HwAArl1vVFmuHt3hu+364q+wXnFLvWW5vvgrpCacDWPq4b0SmvWKW33LKt6oJM5KSkR1YEJUFuhYt1b7G4Tn20/h/M9bAR1GlBT6XW5L+3Wd+1muuA1KpyBfqJ6IwhZ7/OWKV98DKSqhyrK6Tpusi3rsP7WuUzqm1jprqO266TClDoMkyTBfclWV0z8BwHbDLJguHsIvY4moSRj8lQhHfpX71c/EaaqIsb+B0mUAHK/eW2Od0nUgzD1HVNt+DrT8k7D0HwPISpMm9CIiqhD2Qz2y1V7/RrXQso81Wz0sgybA1PUySJIEpdKPoMx90iAndkfEDTNr7GPqOgDWy2/2TtPL0CeiZhL2wd/1gcBnpwwGOaEromesg3XIhS98IyqN4duG34XIyU/6neeGiCgYwn6oR7ZGNMtxdEdBnestgyfBvX9jlWVRv/qz3zNsJFsULIMmQq80syURUaiEffADgKn7lVB/DGyKhtqUvD2nzvXWwZPgPvQR4HHCcvnNsAyZXOdpldYhk5tUHyKixjJE8At3abMeT068GKbOfSBFJVSZWC1q6svQso5VmciMiKi1CUnwFxYW4ve//z0yMjJgsVhw0UUXYeHChWjXrmG/rG0s7fThBm2vdBkA7dShWtfbJzwOSTHXWC6ZrAx9Imr1QvLlriRJuO+++/Dxxx9j8+bN6NKlC5YsWRKKogEAsp+rPdVKscA6aEKdm/gLfSKitiIkwR8XF4ehQ4f67g8cOBBnz54NRdEAAPu438Ey8Gew3/I0pHoucWgZMKbBk7sREbUlkhABTPfYjHRdx7Rp05CWloa77rorlEUD8E6odiL9FwCArg+uwdnXH4d6Lse3vtvv3oRsiUDBZ29DjoiCvftAnF79myrH6D5vfUjrTETUnEIe/AsWLEB2djaWL18OuQEX/sjPd0DXG17VxMRo5Fa7CLfQVUDXIZkscLzxEETZeShJl8Lcd1StV8Fyf7sdrp2vI+reP0EyW/1u01r4a3O4Y5vDn9HaCzStzbIsISEhyv+6plSqodLT03Hy5Em89NJLDQr95ibJJt8PpmyjZ3n/H/XrOi99aOmThugZ61p96BMR1Sdkp3O++OKLOHz4MFavXg2LpfX8StXUMbXGvPtEROEsJMF/7Ngx/OlPf0K3bt3wi194x9dTUlKwYsWKUBRPRESVhCT4L730Unz//fehKIqIiOoR9pO0ERFRVQx+IiKDYfATERkMg5+IyGAY/EREBsPgJyIyGAY/EZHBMPiJiAyGwU9EZDAMfiIig2HwExEZDIOfiMhgGPxERAbD4CciMhgGPxGRwTD4iYgMhsFPRGQwDH4iIoNh8BMRGUxIgj89PR1paWno2bMnjh49GooiiYioFiEJ/lGjRuGtt95C586dQ1EcERHVwRSKQoYMGRKKYoiIKAAc4yciMpiQ9PibQ0JCVKP3TUyMbsaatA1sszEYrc1Gay8QnDa3meDPz3dA10WD90tMjEZubnEQatR6sc3GYLQ2G629QNPaLMtSrR1mDvUQERlMSIL/mWeewbXXXousrCzce++9GD9+fCiKJSIiP0Iy1DN//nzMnz8/FEUREVE9ONRDRGQwDH4iIoNh8BMRGQyDn4jIYBj8REQGw+AnIjIYBj8RkcEw+ImIDIbBT0RkMAx+IiKDYfATERkMg5+IyGAY/EREBsPgJyIyGAY/EZHBMPiJiAyGwU9EZDAMfiIig2HwExEZDIOfiMhgQhb8J06cwB133IExY8bgjjvuwE8//RT0Mg/+kIcjJwuCXg4RUVtiClVBTz31FKZMmYKJEydi06ZNePLJJ/H6668Htcx3Pj2G7MIyXJoSC1XTcSKzGABwTb+OiLCa8On+075tJ4+4GJ3aR+LY6fNISYxCxwQ7khPs+HB3BrbuPokRA5KRNigFZ/IcGHhJIhRZgtWiQBcCuYVlaB9nw+ZdPwEAUhKj0DkxEtF2C774JgsjL++M7IJSSJKEjgl2nHe4IcsSYiMtcHs0/PvgWQxOTUR8tBUAIEkSMvNL8M2JAowc1BkFRfR2VD0AAA4ZSURBVC7E2C0ocXoQH22FJEl+2+t0q7BZvE9pmUuF1aJALt9W03WUuTRE2kwQgG+5P5n5JbDbzDid40Dfi9v53eZ0rgPREWZER1ogAdB0AUWWIIR3vSzXfnxV0+HyaIi0mWvdpi5CCJQ4VVjNCsymC32XUqcKq0WGIjdvf6bE6YHdaqr1cW+MMpeKCGvj//xKnZ6At3V5NMgSYDYpAW2v6wJOtwa7zQSPqkFR5DpfL4ESQqDMpcLeyOfdH5dbgyzX3ja3R8O5EjfO5DhweWoiAO/rT9cFLObaHw9V0+H2aCh1qmgfF1GlDYXFLrSLsdW6rxACpS7V9/r2qN7yFEWCpglYLTXLLXV6fI+LLgScLu/jHyySEBV/qsGTn5+PMWPGYM+ePVAUBZqmYejQodi2bRvatfMfLDWP4YCuN6yq057b3pjqEhlGfLQVhcWulq4G1WL4ZZ0w7aZejdpXliUkJET5XReSHn9mZiaSkpKgKN53OkVR0KFDB2RmZgYc/LU1oC7rnrwR9yzc1uD9iIyCod+67Tx4Fr+fOqRZP20CIRzqaarG9PgBYPMLE5Gb6x3i8ag6TIoETReQZcn78UuWqjyoFUMkLrcGi1mGqgrIMmBSvMMHmi4gSxJKXSqiIsxwuTUoioSiEjfsNhOE8G5jLf8YqWo6JAkwm7wfl4tK3PCoOiJsJmi6gMut+Y4tSwAkCRaTjNxzZXCrOmLsZnhUHXabGZquI8JqgkmRUepUkX/eiQibCVJ5OWaTDLdHR2xcBFxlbmQXlEGSvMM6NouCMpeKKLsZEiSYFAkWs4K8c2XQBWBSJHhUHdF2C86XuBAZYYYQQEmZB1azAqtFgdujAQAUWUapywOzyTvUousCJkWG063C5dGgyLK3zlYFWvkHSovJO+xkMcvIPedEtN0MVdMBAKK8fMA7zFXqVCHLEmIizb4hHZtFQalThUfTYbeacM7hgiLLUDXvY5KYEIXz50shBFDm9j43AHDO4YLLoyHaboGq6pBlCXFRVm+7LAqcbg1CCOi6gABgNSuQJG99VV33Pp+a939R/jgL4f04L0kShBCIsptR5lIhSRI0TYemC5hNMjTN+7houg6zSYFH1aBqwvc6liuGC3UBsyLDUeZBhNWEEqcHsuStp9kko6DYCbvVBEWRva9Ps4JSl4qkxCgUnS/D+RI33B4d0XYzTCbZVweLWYEE71CP2STDalZQ4lQhS4CqeesYFWGGLElweTSUOD2ItnuHHyv+JnThfb1H2kwoKnHDYvbWV9V0KLKEEqeKaLu5Stud5X8Tui4QF22Fquooc2uIjbTAUeZBmUuFxawgymaG06PCZjZBUSScd7ih6QLRdjPOOVyw20woc2mwmGTYLAoiIq3IznXAalbgKHN7X5dmBaomYDJJUDWB8j8hyLIEsyL7/h5jIi1wuTWomg6PpsOsyChzq3CUedApIRJOjwZneb0sJhla+Wu6Ytgmxm4B4M2B/CInACDCokAtzxII72OlyFL5kKO3bkIIuFUdZS4V7aJtyCsqgyLLMJtkRJQP+QjhzZ3ICLPvbyzaboEuBC7tloC8PEeDc6/i9dWiPf7k5GRkZ2dD0zTfUE9OTg6Sk5NDUbxPxXhwRcjISs130Ypx14r/FUvV9RX7VgRLxXhdbWN+lcegASA2ylp1A7v/unZNiva/opzVrPi+E6guMTEaubnFSIqv5eCVt600fnlB3WU3VX1tawxvm5tv7Lg1uaij/8er4nk2isTEaOQm1P+aDrbano9AXILYBm0fH2NDbm7g3+cEKiRn9SQkJKB3797YsmULAGDLli3o3bt3wMM8RETUfEI21PP000/j0UcfxSuvvIKYmBikp6eHqmgiIqokZMHfo0cPvPfee6EqjoiIasFf7hIRGQyDn4jIYBj8REQG02bO469rCoBg7ttWsc3GYLQ2G629QOPbXNd+IZmygYiIWg8O9RARGQyDn4jIYBj8REQGw+AnIjIYBj8RkcEw+ImIDIbBT0RkMAx+IiKDYfATERlM2Ab/iRMncMcdd2DMmDG444478NNPP7V0lRolPT0daWlp6NmzJ44ePepbXlf7GruutSgsLMSvfvUrjBkzBjfffDNmz56NgoICAMDXX3+NCRMmYMyYMZg2bRry8/N9+zV2XWswc+ZMTJgwAZMmTcKUKVPw3XffAQjv57nC8uXLq7y+w/U5BoC0tDSMHTsWEydOxMSJE7Fjxw4ALdBmEaamTp0qNm7cKIQQYuPGjWLq1KktXKPG2bt3rzh79qwYOXKk+P77733L62pfY9e1FoWFhWL37t2++88995x47LHHhKZp4oYbbhB79+4VQgixYsUK8eijjwohRKPXtRZFRUW+25988omYNGmSECK8n2chhDh8+LCYPn267/Udzs+xEKLG37EQjW9XU9oclsGfl5cnBg8eLFRVFUIIoaqqGDx4sMjPz2/hmjVe5RdMXe1r7LrW7KOPPhJ33323OHjwoBg/frxveX5+vhg4cKAQQjR6XWu0YcMGMXny5LB/nl0ul7j99tvFqVOnfK/vcH+O/QV/S7S5zczO2RCZmZlISkqCongvhK4oCjp06IDMzMywuM5vXe0TQjRqXWt9XHRdx1//+lekpaUhMzMTnTp18q1r164ddF3HuXPnGr0uLi4upO2py7x587Br1y4IIbBmzZqwf55ffvllTJgwASkpKb5l4f4cA8AjjzwCIQQGDx6MOXPmtEibw3aMn8LD//3f/8Fut+POO+9s6aoE3aJFi/DZZ5/hN7/5DRYvXtzS1QmqAwcO4PDhw5gyZUpLVyWk3nrrLbz//vtYv349hBBYuHBhi9QjLIM/OTkZ2dnZ0DQNAKBpGnJycpCcnNzCNWsedbWvsetao/T0dJw8eRIvvfQSZFlGcnIyzp4961tfUFAAWZYRFxfX6HWt0aRJk7Bnzx507NgxbJ/nvXv34vjx4xg1ahTS0tKQlZWF6dOn4+TJk2H9HFc8BxaLBVOmTMFXX33VIq/rsAz+hIQE9O7dG1u2bAEAbNmyBb17925VH3Oboq72NXZda/Piiy/i8OHDWLFiBSwWCwCgX79+cDqd2LdvHwDgnXfewdixY5u0rjUoKSlBZmam7/727dsRGxsb1s/zjBkzsHPnTmzfvh3bt29Hx44dsXbtWtx3331h+RwDQGlpKYqLiwEAQghs3boVvXv3bpHXddheiOX48eN49NFHUVRUhJiYGKSnp6N79+4tXa0Ge+aZZ7Bt2zbk5eUhPj4ecXFx+OCDD+psX2PXtRbHjh3Dz372M3Tr1g02mw0AkJKSghUrVuCrr77CU089BZfLhc6dO+P5559H+/btAaDR61paXl4eZs6cibKyMsiyjNjYWMydOxd9+/YN6+e5srS0NKxatQqpqalh+RwDwKlTp/DAAw9A0zTouo4ePXpg/vz56NChQ8jbHLbBT0RE/oXlUA8REdWOwU9EZDAMfiIig2HwExEZDIOfiMhgGPxEQXL69Gn07NkTqqq2dFWIqmDwExEZDIOfiMhgGPxkKNnZ2XjggQdw1VVXIS0tDa+//joAYNmyZXjwwQfx8MMP4/LLL8fkyZNx5MgR337Hjx/H1KlTMWTIEIwfPx6ffvqpb53T6cRzzz2HkSNHYvDgwfjlL38Jp9PpW79582Zcf/31GDp0KFauXOlbfujQIdxyyy0YNGgQrrnmGjz77LMheASIEL4XYiGqTtM0MXnyZLFs2TLhcrlERkaGSEtLE59//rlYunSp6NOnj/jwww+F2+0Wa9asESNHjhRut1u43W5xww03iJUrVwqXyyX+85//iIEDB4rjx48LIYR4+umnxZ133imysrKEqqpi//79wuVyiVOnTonU1FQxb948UVZWJr777jvRt29f8cMPPwghhLj99tvFhg0bhBBCOBwOceDAgRZ7bMhY2OMnw/jvf/+LgoICzJ49GxaLBV26dMHtt9+OrVu3AgD69u2LsWPHwmw2495774Xb7cbBgwdx8OBBlJaWYsaMGbBYLLj66qsxcuRIfPDBB9B1HevXr8e8efN8c+APGjTIN7EcAMyePRs2mw29evVCr169fJ8kTCYTMjIyUFBQgMjISAwcOLBFHhcynrC8EAuRP2fOnEFOTg6GDBniW6ZpGoYMGYJOnTqhY8eOvuWyLCMpKQk5OTkAgI4dO0KWL/STOnXqhOzsbBQWFsLlcqFLly61llt50qyIiAiUlpYC8M6/v3TpUtx0001ISUnB7NmzMXLkyGZrL1FtGPxkGMnJyUhJScG2bdtqrFu2bBmysrJ893VdR3Z2Njp06AAAyMrKgq7rvvDPzMxEt27dEB8fD6vVilOnTqFXr14Nqk+3bt3w4osvQtd1bNu2DQ8++CD27NkDu93ehFYS1Y9DPWQYAwYMQGRkJFavXg2n0wlN03D06FEcOnQIAPDNN99g27ZtUFUVr732GiwWCy677DIMGDAANpsNa9asgcfjwZ49e7B9+3aMGzcOsizj1ltvxbPPPuu7+MmBAwfgdrvrrc+mTZt8F8+IiYkBgCqfKoiCha8yMgxFUbBq1SocOXIEo0aNwlVXXYX58+fD4XAAAEaNGoWtW7fiiiuuwKZNm7Bs2TKYzWZYLBasWrUKn3/+Oa666iosWLAAixcvRo8ePQAAc+fORWpqKm677TZceeWVWLJkCXRdr7c+O3bswPjx43H55Zdj0aJF+OMf/+i7/gBRMHE+fiJ4h3pOnjyJJUuWtHRViIKOPX4iIoNh8BMRGQyHeoiIDIY9fiIig2HwExEZDIOfiMhgGPxERAbD4CciMhgGPxGRwfw/kQli76Icvz8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}